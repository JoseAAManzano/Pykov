{"name":"Pykov","tagline":"Pykov is a tiny Python module on finite regular Markov chains.","body":"Welcome to Pykov docs\r\n====================\r\n\r\nPykov is a tiny Python module on *finite regular Markov chains*.\r\n\r\nYou can define a Markov chain from scratch or read it from a text file according specific format. Pykov is versatile, being it able to manipulate the chain, inserting and removing nodes, and to calculate various kind of quantities, like the steady state distribution, mean first passage times, random walks, absorbing times, and so on.\r\n\r\nPykov is licensed under the terms of the **GNU General Public License** as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\r\n\r\n---------------\r\n\r\nInstallation\r\n-------------\r\nPykov can be installed/upgraded via [`pip`<i class=\"icon-forward\"></i>](http://pip.readthedocs.org/en/latest/#) \r\n```sh\r\n$ pip install git+git://github.com/riccardoscalco/Pykov@master #both Python2 and Python3\r\n$ pip install --upgrade git+git://github.com/riccardoscalco/Pykov@master\r\n```\r\nNote that Pykov depends on **numpy** and **scipy**.\r\n\r\n-----------------\r\n\r\nGetting started\r\n------------------\r\n\r\nOpen your favourite Python shell and import pykov:\r\n```python\r\n>>> import pykov\r\n>>> pykov.__version__\r\n```\r\n\r\n###Vector class\r\nThe **Vector class** inherits from python `dict`, which means it has the same behaviors and features of python dictionaries, with few exceptions. The states and the corresponding probabilities are the keys and the values of the dictionary, respectively.\r\n\r\nDefinition of a `pykov.Vector()`:\r\n```python\r\n>>> p = pykov.Vector()\r\n```\r\nYou can *get* and *set* states in many ways:\r\n```python\r\n>>> p['A'] = .2\r\n>>> p\r\n{'A': 0.2}\r\n\r\n>>> p = pykov.Vector({'A':.3, 'B':.7})\r\n>>> p\r\n{'A':0.3, 'B':0.7}\r\n\r\n>>> pykov.Vector(A=.3, B=.6, C=.1)\r\n{'A':0.3, 'B':0.6, 'C':0.1}\r\n```\r\nStates not belonging to the vector have zero probability, moreover states with zero probability are not shown:\r\n```python\r\n>>> q = pykov.Vector(C=.4, B=.6)\r\n>>> q['C']\r\n0.4\r\n>>> q['Z']\r\n0.0\r\n>>> 'Z' in q\r\nFalse\r\n\r\n>>> q['Z']=.2\r\n>>> q\r\n{'C': 0.4, 'B': 0.6, 'Z': 0.2}\r\n>>> 'Z' in q\r\nTrue\r\n>>> q['Z']=0\r\n>>> q\r\n{'C': 0.4, 'B': 0.6}\r\n>>> 'Z' in q\r\nFalse\r\n```\r\n\r\n#### Vector operations\r\n##### **Sum**\r\nA `pykov.Vector()` instance can be added or substracted to another `pykov.Vector()` instance:\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> q = pykov.Vector(C=.5, B=.5)\r\n>>> p + q\r\n{'A': 0.3, 'C': 0.5, 'B': 1.2}\r\n>>> p - q\r\n{'A': 0.3, 'C': -0.5, 'B': 0.2}\r\n>>> q - p\r\n{'A': -0.3, 'C': 0.5, 'B': -0.2}\r\n```\r\n\r\n##### **Product**\r\nA `pykov.Vector()` instance can be multiplied by a scalar. The *dot product* with another `pykov.Vector()` or `pykov.Matrix()` instance is also supported.\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> p * 3\r\n{'A': 0.9, 'B': 2.1}\r\n>>> 3 * p\r\n{'A': 0.9, 'B': 2.1}\r\n>>> q = pykov.Vector(C=.5, B=.5)\r\n>>> p * q\r\n0.35\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> p * T\r\n{'A': 0.91, 'B': 0.09}\r\n>>> T * p\r\n{'A': 0.42, 'B': 0.3}\r\n```\r\n\r\n#### Vector methods\r\n\r\n#####**sum()**\r\nSum the probability values.\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> p.sum()\r\n1.0\r\n```\r\n\r\n#####**sort(reverse=False)**\r\nReturn a list of tuples `(state, probability)` sorted according the probability values.\r\n```python\r\n>>> p = pykov.Vector({'A':.3, 'B':.1, 'C':.6})\r\n>>> p.sort()\r\n[('B', 0.1), ('A', 0.3), ('C', 0.6)]\r\n>>> p.sort(reverse=True)\r\n[('C', 0.6), ('A', 0.3), ('B', 0.1)]\r\n```\r\n#####**choose()**\r\nChoose a state at random, according to its probability.\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> p.choose()\r\n'B'\r\n>>> p.choose()\r\n'B'\r\n>>> p.choose()\r\n'A'\r\n```\r\n\r\n#####**normalize()**\r\nNormalize the `pykov.Vector`, after normalization the probabilities sum to 1.\r\n```python\r\n>>> p = pykov.Vector({'A':3, 'B':1, 'C':6})\r\n>>> p.sum()\r\n10.0\r\n>>> p.normalize()\r\n>>> p\r\n{'A': 0.3, 'C': 0.6, 'B': 0.1}\r\n>>> p.sum()\r\n1.0\r\n```\r\n\r\n#####**copy()**\r\nReturn a shallow copy.\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> q = p.copy()\r\n>>> p['C'] = 1.\r\n>>> q\r\n{'A': 0.3, 'B': 0.7}\r\n```\r\n\r\n#####**entropy()**\r\nReturn the Shannon entropy, defined as $H(p) = \\sum_i p_i \\ln p_i$.\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> p.entropy()\r\n0.6108643020548935\r\n```\r\nFor further details, have a look at *Khinchin A. I., Mathematical Foundations of Information Theory Dover, 1957*.\r\n\r\n#####**dist(q)**\r\nReturn the distance to another `pykov.Vector`, defined as $d(p,q) = \\sum_i | p_i - q_i |$. \r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> q = pykov.Vector(C=.5, B=.5)\r\n>>> p.dist(q)\r\n1.0\r\n```\r\n\r\n#####**relative_entropy(q)**\r\nReturn the *Kullback-Leibler* distance, defined as $d(p,q) = \\sum_i p_i \\ln (p_i/q_i)$.\r\n```python\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> q = pykov.Vector(A=.4, B=.6)\r\n>>> p.relative_entropy(q) #d(p,q)\r\n0.02160085414354654\r\n>>> q.relative_entropy(p) #d(q,p)\r\n0.022582421084357485\r\n```\r\nNote that the Kullback-Leibler distance is not symmetric.\r\n\r\n------------\r\n\r\n###Matrix class\r\nThe `pykov.Matrix()` class inherits from python dictionaries. Dict `keys` are `tuple` of states, dict `values` are the matrix entries. Indexes do not need to be `int`, they can be `string`, as the states of a `pykov.Vector()`.\r\n\r\nDefinition of  `pykov.Matrix()`:\r\n```python\r\n>>> T = pykov.Matrix()\r\n```\r\nYou can *get* and *set* items in many ways:\r\n```python\r\n>>> T = pykov.Matrix()\r\n>>> T[('A','B')] = .3\r\n>>> T\r\n{('A', 'B'): 0.3}\r\n>>> T['A','A'] = .7\r\n>>> T\r\n{('A', 'B'): 0.3, ('A', 'A'): 0.7}\r\n\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T[('A','B')]\r\n0.3\r\n>>> T['A','B']\r\n0.3\r\n```\r\nItems not belonging to the matrix have value equal to zero, moreover items with value equal to zero are not shown:\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T['B','B']\r\n0.0\r\n\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T\r\n{('A', 'B'): 0.3, ('A', 'A'): 0.7, ('B', 'A'): 1.0}\r\n>>> T['A','A'] = 0\r\n>>> T\r\n{('A', 'B'): 0.3, ('B', 'A'): 1.0}\r\n```\r\n\r\n#### Matrix operations\r\n\r\n##### **Sum**\r\nA `pykov.Matrix()` instance can be added or substracted to another `pykov.Matrix()` instance.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> I = pykov.Matrix({('A','A'):1, ('B','B'):1})\r\n>>> T + I\r\n{('B', 'A'): 1.0, ('A', 'B'): 0.3, ('A', 'A'): 1.7, ('B', 'B'): 1.0}\r\n>>> T - I\r\n{('B', 'A'): 1.0, ('A', 'B'): 0.3, ('A', 'A'): -0.3, ('B', 'B'): -1}\r\n```\r\n\r\n##### **Product**\r\nA `pykov.Matrix()` instance can be multiplied by a scalar, the dot product with a `pykov.Vector()` or another `pykov.Matrix()` instance is also supported.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T * 3\r\n{('B', 'A'): 3.0, ('A', 'B'): 0.9, ('A', 'A'): 2.1}\r\n\r\n>>> p = pykov.Vector(A=.3, B=.7)\r\n>>> T * p\r\n{'A': 0.42, 'B': 0.3}\r\n\r\n>>> W = pykov.Matrix({('N', 'M'): 0.5, ('M', 'N'): 0.7,\r\n                      ('M', 'M'): 0.3, ('O', 'N'): 0.5,\r\n                      ('O', 'O'): 0.5, ('N', 'O'): 0.5})\r\n>>> W * W\r\n{('N', 'M'): 0.15, ('M', 'N'): 0.21, ('M', 'O'): 0.35,\r\n ('M', 'M'): 0.44, ('O', 'M'): 0.25, ('O', 'N'): 0.25,\r\n ('O', 'O'): 0.5, ('N', 'O'): 0.25, ('N', 'N'): 0.6}\r\n```\r\n\r\n#### Matrix methods\r\n\r\n#####**states()**\r\nReturn the `set` of states.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.states()\r\n{'B', 'A'}\r\n```\r\nStates without ingoing or outgoing transitions are removed from the set of states.\r\n```python\r\n>>> T['A','C']=1\r\n>>> T.states()\r\n{'A', 'C', 'B'}\r\n>>> T['A','C']=0\r\n>>> T.states()\r\n{'A', 'B'}\r\n```\r\n\r\n#####**pred(key=None)**\r\nReturn the precedessors of a state (if not indicated, of all states). In matrix notation, return the column of the indicated state.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.pred()\r\n{'A': {'A': 0.7, 'B': 1.0}, 'B': {'A': 0.3}}\r\n>>> T.pred('A')\r\n{'A': 0.7, 'B': 1.0}\r\n```\r\n\r\n#####**succ(key=None)**\r\nReturn the successors of a state (if not indicated, of all states). In matrix notation, return the row of the indicated state.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.succ()\r\n{'A': {'A': 0.7, 'B': 0.3}, 'B': {'A': 1.0}}\r\n>>> T.succ('A')\r\n{'A': 0.7, 'B': 0.3}\r\n```\r\n\r\n#####**copy()**\r\nReturn a shallow copy.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> W = T.copy()\r\n>>> T[('B','B')] = 1.\r\n>>> W\r\n{('B', 'A'): 1.0, ('A', 'B'): 0.3, ('A', 'A'): 0.7}\r\n```\r\n\r\n#####**remove(states)**\r\nReturn a shallow copy of the matrix without the indicated states.\r\nAll the links where the states appear are deleted, so that the result will not be in general a stochastic matrix.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.remove(['B'])\r\n{('A', 'A'): 0.7}\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.,\r\n                     ('C','D'): .5, ('D','C'): 1., ('C','B'): .5})\r\n>>> T.remove(['A','B'])\r\n{('C', 'D'): 0.5, ('D', 'C'): 1.0}\r\n```\r\n\r\n#####**stochastic()**\r\nChange the `pykov.Matrix()` instance in a right [stochastic matrix](http://en.wikipedia.org/wiki/Stochastic_matrix).\r\nSet the sum of every row equal to one, raise `PykovError` if not possible.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): 3, ('A','A'): 7, ('B','A'): .2})\r\n>>> T.stochastic()\r\n>>> T\r\n{('B', 'A'): 1.0, ('A', 'B'): 0.3, ('A', 'A'): 0.7}\r\n\r\n>>> T[('A','C')]=1\r\n>>> T.stochastic()\r\npykov.PykovError: 'Zero links from node C'\r\n```\r\n\r\n#####**transpose()**\r\nReturn the transpose of the `pykov.Matrix()` instance.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.transpose()\r\n{('B', 'A'): 0.3, ('A', 'B'): 1.0, ('A', 'A'): 0.7}\r\n>>> T\r\n{('A', 'B'): 0.3, ('A', 'A'): 0.7, ('B', 'A'): 1.0}\r\n```\r\n\r\n#####**eye()**\r\nReturn the [Identity matrix](http://en.wikipedia.org/wiki/Identity_matrix).\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.eye()\r\n{('A', 'A'): 1., ('B', 'B'): 1.}\r\n>>> type(T.eye())\r\n<class 'pykov.Matrix'>\r\n```\r\n\r\n#####**ones()**\r\nReturn a `pykov.Vector()` instance with entries equal to 1.\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.ones()\r\n{'A': 1.0, 'B': 1.0}\r\n>>> type(T.ones())\r\n<class 'pykov.Vector'>\r\n```\r\n\r\n#####**trace()**\r\nReturn the matrix [trace](http://en.wikipedia.org/wiki/Trace_%28linear_algebra%29).\r\n```python\r\n>>> T = pykov.Matrix({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.trace()\r\n0.7\r\n```\r\n\r\n---------------\r\n\r\n###Chain class\r\n\r\nThe `pykov.Chain` class inherits from `pykov.Matrix` class.\r\nThe dict `key` is a tuple of states, the dict `value` is the transition\r\nprobability to go from the first state to the second state, in other words\r\npykov describes the transitions of a Markov chain with a *right* stochastic matrix.\r\n\r\n#### Chain methods\r\n\r\n#####**adjacency()**\r\nReturn the [adjacency matrix](http://en.wikipedia.org/wiki/Adjacency_matrix).\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.adjacency()\r\n{('B', 'A'): 1, ('A', 'B'): 1, ('A', 'A'): 1}\r\n>>> type(T.adjacency())\r\n<class 'pykov.Matrix'>\r\n```\r\n\r\n#####**pow(p, n)**\r\nFind the probability distribution after `n` steps, starting from an initial `pykov.Vector()` `p`.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> p = pykov.Vector(A=1)\r\n>>> T.pow(p,3)\r\n{'A': 0.7629999999999999, 'B': 0.23699999999999996}\r\n>>> p * T * T * T #not efficient\r\n{'A': 0.7629999999999999, 'B': 0.23699999999999996}\r\n```\r\n\r\n#####**move(state)**\r\nDo one step from the indicated `state` to one of its successors, chosen at random according to the transition probability. Return the new state.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.move('A')\r\n'B'\r\n```\r\n\r\n#####**walk(steps, start=None, stop=None)**\r\nReturn a random walk of n `steps`, starting and stopping at the indicated states.  If not indicated, then the starting state is chosen according to the steady state probability. If the stopping state is reached before to do n steps, then the walker stops.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.walk(10)\r\n['B', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A']\r\n>>> T.walk(10,'B','B')\r\n['B', 'A', 'A', 'A', 'A', 'A', 'B']\r\n```\r\n\r\n#####**walk_probability(walk)**\r\nReturn the *logarithm* of the **walk** probability (see `walk()` method). Impossible walks have probability equal to zero.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.walk_probability(['A','A','B','A','A'])\r\n-1.917322692203401\r\n>>> probability = math.exp(-1.917322692203401)\r\n>>> probability\r\n0.147\r\n\r\n>>> p = T.walk_probability(['A','B','B','B','A'])\r\n>>> math.exp(p)\r\n0.0\r\n```\r\n\r\n\r\n#####**steady()**\r\nReturn the steady state, i.e. the equilibrium distribution of the chain.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.steady()\r\n{'A': 0.7692307692307676, 'B': 0.23076923076923028}\r\n```\r\nSince Pykov describes the chain with a right stochatic matrix,\r\nthe steady state $x$ satisfies at the condition $p=pT$\r\nand it is calculated with the *inverse iteration method* \r\n$Q^t x = e$, where $Q = I - T$ and $e = (0,0,...,1)$.\r\nMoreover, the Markov chain is assumed to be ergodic, i.e. the transition matrix\r\nmust be irreducible and acyclic.\r\nYou can easily test such properties by means of\r\n[NetworkX](http://networkx.github.io/), let's see how:\r\n```python\r\n>>> import networkx as nx\r\n\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> G = nx.DiGraph(list(T.keys()))\r\n>>> nx.is_strongly_connected(G) # is irreducible\r\nTrue\r\n>>> nx.is_aperiodic(G)\r\nTrue\r\n\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','B'): 1.})\r\n>>> G = nx.DiGraph(list(T.keys()))\r\n>>> nx.is_strongly_connected(G) # is irreducible\r\nFalse\r\n>>> nx.is_aperiodic(G)\r\nTrue\r\n\r\n>>> T = pykov.Chain({('A','B'): 1, ('B','C'): 1., ('C','A'): 1.})\r\n>>> G = nx.DiGraph(list(T.keys()))\r\n>>> nx.is_strongly_connected(G)\r\nTrue\r\n>>> nx.is_aperiodic(G)\r\nFalse\r\n```\r\n\r\nOften, Markov chains created from raw data are not irreducibles.\r\nIn such cases, the Markov chain may be defined by means of the\r\nlargest strongly connected component of the associated graph.\r\nStrongly connected components can be found with NetworkX:\r\n```python\r\n>>> nx.strongly_connected_components(G)\r\n```\r\n\r\nFor further details on the inverse iteration method,\r\nhave a look at *W. Stewart, Introduction to the Numerical Solution of\r\nMarkov Chains, Princeton University Press, Chichester, West Sussex, 1994*.\r\n\r\n#####**mixing_time(cutoff=0.25, jump=1, p=None)**\r\nReturn the [mixing time](http://en.wikipedia.org/wiki/Markov_chain_mixing_time), defined as the number of steps needed to have $|pT^n - \\pi|<0.25$, where $\\pi$ is the steady state $\\pi = \\pi T$.\r\n\r\nIf the initial distribution `p` is not indicated, then the iteration starts from the less probable state of the steady distribution. The parameter `jump` controls the iteration step, for example with `jump=2` n has values 2,4,6,8,..\r\n```python\r\n>>> d = {('R','R'):1./2, ('R','N'):1./4, ('R','S'):1./4,\r\n         ('N','R'):1./2, ('N','N'):0., ('N','S'):1./2,\r\n         ('S','R'):1./4, ('S','N'):1./4, ('S','S'):1./2}\r\n>>> T = pykov.Chain(d)\r\n>>> T.mixing_time()\r\n2\r\n```\r\n\r\n#####**entropy(p=None, norm=False)**\r\nReturn the Chain entropy, defined as $H = \\sum_i \\pi_i H_i$, where $H_i=\\sum_j T_{ij}\\ln T_{ij}$.\r\nIf `p` is not `None`, then the entropy is calculated with the indicated probability `pykov.Vector()`.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.entropy()\r\n0.46989561696530169\r\n```\r\nWith **norm=True** entropy belongs to [0,1].\r\n```python\r\n>>> T.entropy(norm=True)\r\n0.33895603665233132\r\n```\r\nFor further details, have a look at *Khinchin A. I., Mathematical Foundations of Information Theory, Dover, 1957*.\r\n\r\n#####**mfpt_to(state)**\r\nReturn the Mean First Passage Times of every state *to* the indicated `state`.\r\n```python\r\n>>> d = {('R', 'N'): 0.25, ('R', 'S'): 0.25, ('S', 'R'): 0.25,\r\n         ('R', 'R'): 0.5, ('N', 'S'): 0.5, ('S', 'S'): 0.5,\r\n         ('S', 'N'): 0.25, ('N', 'R'): 0.5, ('N', 'N'): 0.0}\r\n>>> T = pykov.Chain(d)\r\n>>> T.mfpt_to('R')\r\n{'S': 3.333333333333333, 'N': 2.666666666666667} #mfpt from 'S' to 'R' is 3.33\r\n```\r\nSee also *Kemeny J. G. and Snell, J. L., Finite Markov Chains. Springer-Verlag: New York, 1976*.\r\n\r\n#####**absorbing_time(transient_set)**\r\nMean number of steps needed to leave the `transient_set`, return the `pykov.Vector()` `tau` where `tau[i]` is the mean number of steps needed to leave the transient set starting from state `i`. The parameter `transient_set` is a subset of states (iterable).\r\n```python\r\n>>> d = {('R','R'):1./2, ('R','N'):1./4, ('R','S'):1./4,\r\n         ('N','R'):1./2, ('N','N'):0., ('N','S'):1./2,\r\n         ('S','R'):1./4, ('S','N'):1./4, ('S','S'):1./2}\r\n>>> T = pykov.Chain(d)\r\n>>> p = pykov.Vector({'N':.3, 'S':.7})\r\n>>> tau = T.absorbing_time(p.keys())\r\n>>> tau\r\n{'S': 3.333333333333333, 'N': 2.6666666666666665}\r\n```\r\nIn other words, the mean number of steps in order to leave states `'S'` and `'N'` starting from `'S'` is 3.33.\r\nIt is sufficient to calculate `p * tau` in order to weight the mean times according an initial distribution `p`.\r\n```python\r\n>>> p * tau\r\n3.1333333333333329\r\n```\r\nIn order to better understand the meaning of the method, the calculation of the previous example can be approximated by means of many random walkers:\r\n```python\r\n>>> numpy.mean([len(T.walk(10000000,\"S\",\"R\"))-1 for i in range(1000000)])\r\n3.3326020000000001\r\n>>> numpy.mean([len(T.walk(10000000,\"N\",\"R\"))-1 for i in range(1000000)])\r\n2.6665549999999998\r\n```\r\n\r\n#####**absorbing_tour(p, transient_set=None)**\r\nReturn a `pykov.Vector()` `v`, where `v[i]` is the mean time the process is in the transient state `i` before leaving the transient set.\r\n\r\nNote that `v.sum()` is equal to `p * tau` (see `absorbing_time()` method).\r\nIf not specified, the transient set is defined as the set of states in vector `p`.\r\n```python\r\n>>> d = {('R','R'):1./2, ('R','N'):1./4, ('R','S'):1./4,\r\n         ('N','R'):1./2, ('N','N'):0., ('N','S'):1./2,\r\n         ('S','R'):1./4, ('S','N'):1./4, ('S','S'):1./2}\r\n>>> T = pykov.Chain(d)\r\n>>> p = pykov.Vector({'N':.3, 'S':.7})\r\n>>> T.absorbing_tour(p)\r\n{'S': 2.2666666666666666, 'N': 0.8666666666666669}\r\n```\r\n\r\n#####**fundamental_matrix()**\r\nReturn the fundamental matrix, have a look at *Kemeny J. G. and Snell J. L., Finite Markov Chains. Springer-Verlag: New York, 1976* for further details.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.fundamental_matrix()\r\n{('B', 'A'): 0.17751479289940991, ('A', 'B'): 0.053254437869822958,\r\n('A', 'A'): 0.94674556213017902, ('B', 'B'): 0.82248520710059214}\r\n```\r\nNote that the fundamental matrix is not sparse.\r\n\r\n#####**kemeny_constant()**\r\nReturn the Kemeny constant of the transition matrix.\r\n```python\r\n>>> T = pykov.Chain({('A','B'): .3, ('A','A'): .7, ('B','A'): 1.})\r\n>>> T.kemeny_constant()\r\n1.7692307692307712\r\n```\r\n\r\n----------------------------\r\n\r\nUtilities\r\n----------\r\nPykov comes with an utility useful to create a `pykov.Chain()` from a text file, let say file `/mypath/mat`, which contains the transition matrix defined with the following format:\r\n```python\r\nA A .7\r\nA B .3\r\nB A 1\r\n```\r\nThe `pykov.Chain()` instance is created with the command:\r\n```python\r\n>>> P = pykov.readmat('/mypath/mat')\r\n>>> P\r\n{('B', 'A'): 1.0, ('A', 'B'): 0.3, ('A', 'A'): 0.7}\r\n```\r\n-----------------------------------\r\n> Docs written with [StackEdit](https://stackedit.io/).\r\n","google":"UA-55880103-1","note":"Don't delete this file! It's used internally to help with page regeneration."}